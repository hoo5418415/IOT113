{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNk60SNY1NWYN5/J7dkBzmG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install optuna pandas scikit-learn xgboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBJt8MHcIibO","executionInfo":{"status":"ok","timestamp":1732535487390,"user_tz":-480,"elapsed":6190,"user":{"displayName":"羅振豪","userId":"14723211076608139947"}},"outputId":"b023d6a8-d095-40fe-ebec-3a08938962f4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.6)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MAU1LttuIglm","outputId":"3fb47322-7e70-4c52-fe61-e47da747c7b2"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-41c633b9be5c>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Age'].fillna(data['Age'].median(), inplace=True)\n","<ipython-input-6-41c633b9be5c>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n","<ipython-input-6-41c633b9be5c>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Fare'].fillna(data['Fare'].median(), inplace=True)\n","<ipython-input-6-41c633b9be5c>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Age'].fillna(data['Age'].median(), inplace=True)\n","<ipython-input-6-41c633b9be5c>:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n","<ipython-input-6-41c633b9be5c>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  data['Fare'].fillna(data['Fare'].median(), inplace=True)\n","[I 2024-11-25 11:53:25,948] A new study created in memory with name: no-name-16164687-4ca2-444d-9dc3-a383d0aca9d3\n","[I 2024-11-25 11:53:26,387] Trial 0 finished with value: 0.8202009258347287 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.03657488803846314, 'n_estimators': 81, 'max_depth': 9, 'colsample_bytree': 0.6434961383877629}. Best is trial 0 with value: 0.8202009258347287.\n","[I 2024-11-25 11:53:26,988] Trial 1 finished with value: 0.7893233527036344 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.15641590204026024, 'n_estimators': 131, 'max_depth': 13, 'colsample_bytree': 0.7461491548282153}. Best is trial 0 with value: 0.8202009258347287.\n","[I 2024-11-25 11:53:27,190] Trial 2 finished with value: 0.8145769723234512 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.17080869649591332, 'n_estimators': 69, 'max_depth': 4, 'colsample_bytree': 0.8103057609195504}. Best is trial 0 with value: 0.8202009258347287.\n","[I 2024-11-25 11:53:28,824] Trial 3 finished with value: 0.8286516300600807 and parameters: {'model_type': 'RandomForest', 'n_estimators': 203, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:29,190] Trial 4 finished with value: 0.7864966019895597 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.18774830312390878, 'n_estimators': 84, 'max_depth': 18, 'colsample_bytree': 0.970828950095697}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:29,506] Trial 5 finished with value: 0.8132079188417217 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.08500339754693209, 'n_estimators': 60, 'max_depth': 17, 'colsample_bytree': 0.6429019090974019}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:31,388] Trial 6 finished with value: 0.8159854230276766 and parameters: {'model_type': 'RandomForest', 'n_estimators': 218, 'max_depth': 39, 'min_samples_split': 2, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:33,090] Trial 7 finished with value: 0.8258150300403819 and parameters: {'model_type': 'RandomForest', 'n_estimators': 201, 'max_depth': 35, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:33,596] Trial 8 finished with value: 0.8187924751305033 and parameters: {'model_type': 'RandomForest', 'n_estimators': 58, 'max_depth': 29, 'min_samples_split': 9, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:35,875] Trial 9 finished with value: 0.8089530188121739 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.03325444785364616, 'n_estimators': 242, 'max_depth': 7, 'colsample_bytree': 0.69612310977742}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:38,573] Trial 10 finished with value: 0.8244262779474048 and parameters: {'model_type': 'RandomForest', 'n_estimators': 286, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:40,001] Trial 11 finished with value: 0.8272530286614794 and parameters: {'model_type': 'RandomForest', 'n_estimators': 176, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:41,367] Trial 12 finished with value: 0.825844577957254 and parameters: {'model_type': 'RandomForest', 'n_estimators': 167, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:42,607] Trial 13 finished with value: 0.821619225844578 and parameters: {'model_type': 'RandomForest', 'n_estimators': 148, 'max_depth': 26, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:44,678] Trial 14 finished with value: 0.8244262779474048 and parameters: {'model_type': 'RandomForest', 'n_estimators': 253, 'max_depth': 34, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:46,248] Trial 15 finished with value: 0.8244459765586527 and parameters: {'model_type': 'RandomForest', 'n_estimators': 191, 'max_depth': 43, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:47,597] Trial 16 finished with value: 0.8244361272530287 and parameters: {'model_type': 'RandomForest', 'n_estimators': 121, 'max_depth': 22, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:50,391] Trial 17 finished with value: 0.8244361272530287 and parameters: {'model_type': 'RandomForest', 'n_estimators': 232, 'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:51,807] Trial 18 finished with value: 0.817393873731902 and parameters: {'model_type': 'RandomForest', 'n_estimators': 168, 'max_depth': 21, 'min_samples_split': 6, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:53,969] Trial 19 finished with value: 0.8174037230375258 and parameters: {'model_type': 'RandomForest', 'n_estimators': 267, 'max_depth': 41, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:55,623] Trial 20 finished with value: 0.8230276765488034 and parameters: {'model_type': 'RandomForest', 'n_estimators': 204, 'max_depth': 16, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:57,094] Trial 21 finished with value: 0.8272530286614794 and parameters: {'model_type': 'RandomForest', 'n_estimators': 176, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:58,588] Trial 22 finished with value: 0.8230375258544272 and parameters: {'model_type': 'RandomForest', 'n_estimators': 183, 'max_depth': 28, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:53:59,796] Trial 23 finished with value: 0.8258544272628778 and parameters: {'model_type': 'RandomForest', 'n_estimators': 150, 'max_depth': 32, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:01,277] Trial 24 finished with value: 0.8258642765685019 and parameters: {'model_type': 'RandomForest', 'n_estimators': 118, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:03,589] Trial 25 finished with value: 0.8188121737417511 and parameters: {'model_type': 'RandomForest', 'n_estimators': 217, 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:04,859] Trial 26 finished with value: 0.8244459765586527 and parameters: {'model_type': 'RandomForest', 'n_estimators': 153, 'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:05,780] Trial 27 finished with value: 0.8230079779375552 and parameters: {'model_type': 'RandomForest', 'n_estimators': 104, 'max_depth': 13, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:07,279] Trial 28 finished with value: 0.8244459765586527 and parameters: {'model_type': 'RandomForest', 'n_estimators': 179, 'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:07,897] Trial 29 finished with value: 0.7879247513050329 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.10882009939105357, 'n_estimators': 219, 'max_depth': 9, 'colsample_bytree': 0.5438213009124426}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:09,531] Trial 30 finished with value: 0.821619225844578 and parameters: {'model_type': 'RandomForest', 'n_estimators': 193, 'max_depth': 36, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:10,591] Trial 31 finished with value: 0.8272628779671033 and parameters: {'model_type': 'RandomForest', 'n_estimators': 127, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:11,706] Trial 32 finished with value: 0.8230473751600513 and parameters: {'model_type': 'RandomForest', 'n_estimators': 136, 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:13,348] Trial 33 finished with value: 0.825844577957254 and parameters: {'model_type': 'RandomForest', 'n_estimators': 166, 'max_depth': 31, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:15,612] Trial 34 finished with value: 0.794907908992416 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.10472125458734642, 'n_estimators': 135, 'max_depth': 18, 'colsample_bytree': 0.9670199710555201}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:15,872] Trial 35 finished with value: 0.8230178272431793 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.13787551095586925, 'n_estimators': 101, 'max_depth': 4, 'colsample_bytree': 0.8441335070850453}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:16,614] Trial 36 finished with value: 0.8188417216586231 and parameters: {'model_type': 'RandomForest', 'n_estimators': 81, 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:17,926] Trial 37 finished with value: 0.8202206244459764 and parameters: {'model_type': 'RandomForest', 'n_estimators': 156, 'max_depth': 14, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:18,651] Trial 38 finished with value: 0.7963163596966414 and parameters: {'model_type': 'XGBoost', 'learning_rate': 0.06044207685296508, 'n_estimators': 212, 'max_depth': 18, 'colsample_bytree': 0.5054322104992455}. Best is trial 3 with value: 0.8286516300600807.\n","[I 2024-11-25 11:54:20,092] Trial 39 finished with value: 0.8244459765586527 and parameters: {'model_type': 'RandomForest', 'n_estimators': 178, 'max_depth': 22, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8286516300600807.\n"]}],"source":["import pandas as pd\n","import optuna\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from xgboost import XGBClassifier\n","\n","# Step 1: Load the Titanic dataset\n","train_data = pd.read_csv(\"train.csv\")\n","test_data = pd.read_csv(\"test.csv\")\n","\n","# Step 2: Preprocess the data\n","def preprocess(data):\n","    # Fill missing values\n","    data['Age'].fillna(data['Age'].median(), inplace=True)\n","    data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n","    data['Fare'].fillna(data['Fare'].median(), inplace=True)\n","\n","    # Convert categorical columns to numeric\n","    label_encoder = LabelEncoder()\n","    for col in ['Sex', 'Embarked']:\n","        data[col] = label_encoder.fit_transform(data[col])\n","\n","    # Drop unnecessary columns\n","    data.drop(columns=['Name', 'Ticket', 'Cabin'], inplace=True, errors='ignore')\n","    return data\n","\n","# Preprocess train and test datasets\n","train_data = preprocess(train_data)\n","test_data = preprocess(test_data)\n","\n","# Separate features and target\n","X = train_data.drop(columns=['Survived'])\n","y = train_data['Survived']\n","X_test = test_data\n","\n","# Split train data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=123)\n","\n","# Step 3: Define the Optuna objective function\n","def objective(trial):\n","    # Suggest hyperparameters\n","    model_type = trial.suggest_categorical(\"model_type\", [\"RandomForest\", \"XGBoost\"])\n","\n","    if model_type == \"RandomForest\":\n","        n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n","        max_depth = trial.suggest_int(\"max_depth\", 5, 50)\n","        min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n","        min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 4)\n","\n","        model = RandomForestClassifier(\n","            n_estimators=n_estimators,\n","            max_depth=max_depth,\n","            min_samples_split=min_samples_split,\n","            min_samples_leaf=min_samples_leaf,\n","            random_state=123\n","        )\n","\n","    elif model_type == \"XGBoost\":\n","        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.2)\n","        n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n","        max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n","        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n","\n","        model = XGBClassifier(\n","            learning_rate=learning_rate,\n","            n_estimators=n_estimators,\n","            max_depth=max_depth,\n","            colsample_bytree=colsample_bytree,\n","            random_state=123,\n","            #use_label_encoder=False,\n","            eval_metric='logloss'\n","        )\n","\n","    # Evaluate the model using cross-validation\n","    score = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n","    return score\n","\n","# Step 4: Run Optuna optimization\n","study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=50)\n","\n","# Best hyperparameters\n","print(\"Best hyperparameters:\", study.best_params)\n","\n","# Step 5: Train the final model with optimal parameters\n","best_params = study.best_params\n","\n","if best_params[\"model_type\"] == \"RandomForest\":\n","    final_model = RandomForestClassifier(\n","        n_estimators=best_params[\"n_estimators\"],\n","        max_depth=best_params[\"max_depth\"],\n","        min_samples_split=best_params[\"min_samples_split\"],\n","        min_samples_leaf=best_params[\"min_samples_leaf\"],\n","        random_state=123\n","    )\n","elif best_params[\"model_type\"] == \"XGBoost\":\n","    final_model = XGBClassifier(\n","        learning_rate=best_params[\"learning_rate\"],\n","        n_estimators=best_params[\"n_estimators\"],\n","        max_depth=best_params[\"max_depth\"],\n","        colsample_bytree=best_params[\"colsample_bytree\"],\n","        random_state=123,\n","        eval_metric='logloss'\n","    )\n","\n","final_model.fit(X_train, y_train)\n","\n","# Step 6: Evaluate on the validation set\n","accuracy = final_model.score(X_val, y_val)\n","print(f\"Validation Accuracy: {accuracy:.2f}\")\n","\n","# Step 7: Make predictions on the test dataset\n","predictions = final_model.predict(X_test)\n","print(\"Test Predictions:\", predictions[:10])"]}]}